# 2018 并发编程

## 第一节

目标

### 1、多线程的发展历史

进程，一次性加载到内存中  CPU时间片，进程只能干一件事情，一个进程包含多个线程

线程

硬件的架构

什么时候使用多线程?

1、通过并行计算提高程序性能

2、等待网络/IO响应导致的耗时问题

### 2、线程的应用

线程有三种实现方式，一种是集成thread类，另一种是实现Runnable接口 ，第三种callable,future

LinkedBlockingQueue

### 3、并发编程的基础

线程的状态：6种

1、NEW

```
A thread that has not yet started is in this state.
初始状态，没有调用start方法
```

2、RUNNABLE

```
A thread executing in the Java virtual machine is in this state.
运行状态，在这之前还有个就绪（READY）
```

3、BLOCKED

```
A thread that is blocked waiting for a monitor lock
    is in this state.
阻塞
	等待阻塞  wait
	同步阻塞  synchrnoized
	其他阻塞  sleep、join
synchronized
```

4、WAITING

```
 A thread that is waiting indefinitely for another thread to
     perform a particular action is in this state.
     等待
```

5、 TIME_WAITING

```
A thread that is waiting for another thread to perform an action
     for up to a specified waiting time is in this state.
时间等待
seelp/wait/join/LockSupport.park()
notify/notifyall/LockSupport.unpark()
```

6、TERMINATED

```
A thread that has exited is in this state.
退出线程的状态
```

cmd jps jstack,查询线程的状态

线程的启动和终止

启动：start，native

终止：stop,一般不用，用优雅的关闭。

​	interrupt:  native方法，原理与volatile一样

​	通过指令的方式:volatile boolean isStop=false,

thread.isInterrupted:返回的结果

Thread.interrupted():对线程的一个复位

### 4、线程安全问题

* 可见性、原子性、有序性

可见性：volatile

原子性（Atomic）：

CPU的高速缓存：

L1---L1 d    L1 i

L2  chche

寄存器

共享    L3 cache

---------------------------------------

主内存



* 缓存一致性的问题？如何解决？

cpu提供了两种方式，

1、总线锁（排它锁），有性能的问题

2、缓存锁：只锁缓存的数据，MESI协议，汇编指令加个LOCK的指令，

MESI协议：在每个缓冲缓存一个标记位

​	M（modify）:当前的缓冲被修改过，

​	I(Invalid)：缓冲失效了

​	E(Exclusive)：独占缓存

​	s(Shared)：共享缓冲

​	嗅探协议

* JMM（应用层面）：

是抽象的内存模型，主要解决可见性、原子性、有序性

java线程--》工作内存（高速缓存）---》load(加载)/store---》主内存（实例对象、静态字段、数组对象）

use 《--load 《---read《---lock

assign--》store---》wite---》unlock

lock：是开发性的(monitorenter/volatile)

## 第二节

### 1、JMM内存模型

*  因为可见性导致的原子性的问题 两个线程同时加1，导致小于3
* 有序性有三个原因
  * 编译器的执行重排序
  * 处理器的指令重拍下
  * 内存系统的重排序

### 2、JMM如果解决原子性、可见性、有序性的问题

* volatile/synchronized/final/j.u.c(java.util.concurrent)
* 原子性  synchronized（monitorenter/monitorexit）
* 可见性 volatile/synchronized/final
* 有序性 volatile/synchronized

### 3、Volatile和synchronized的原理

* volatile  

  * 是轻量级的锁（解决可见性（lock），防止指令重排序），通过指令添加了lock在CPU高速缓存中

  * as-if-serial 

    

    怎么防止指令重排序的？

* 内存屏障

  * 优化屏障
  * 内存屏障
    - 在CPU方面了解什么是内存屏障
      - 高速缓存，数据一致性
    - 乱序访问
    - 在linuxX86上store barrier、load barrier/full barries,解决了顺序重排 的问题，不能解决缓存一致性的问题
      - 防止指令之间的重排序
      - 保证数据的可见性
      - store barrier（写屏障-storestore barrier），强制所有的在storestore内存屏障之前的所有指令先执行、并且发送缓存失效的信号，所有在storestore barrier内存屏障指令之后的store指令，必须在storestore内存屏障之前的指令执行之后再执行。
      - load barrier（读屏障）loadload barrier 
      - storeload (full barries)

* 编译器层面如何解决指令重排序问题？

  * volatile-->flags:ACC_VOLATILE 在accessFlags.hpp-->bytechodeIntepreter.cpp

    ```c++
    int field offset=cache->f2_as_index();
    	if(cache->is_volatile){
    		if(tos_type ==itos){//int,long,char,byte,short,float,double}
    	}
    obj->release int field put(field offset,STACK_INT（-1）)；//值的存储
    
    ```

    oop.inline.cpp

    ```c++
    static void release_store(volatile jint* p,jint  v);
    inline void OrderAccess::release_store(volatile jint* p,jint  v){*p=v;}//语言解绑的内存屏障
    ```

    1、对每天volatile写操作的前面插入storestore barrie

    2、对每个volatile写后面的操作插入storeload barrie

    3、对每个volatile读操作前面插入loadload barrie

    4、对每个volatile读操作后面插入loadstore barrie

    ```c++
    if(os::is MP()){
        //slways use locked addl since is sometimes expensive
    #ifdef AMD64
    	asm volatile("lock;addl$0,0(%%rsp)":::"cc","memory");
    #else
    	asm volatile("lock;addl$0,0(%%esp)":::"cc","memory");
    #endif
    ```

    

* 原则性，对复合操作的原则性是没办法的，

  * getfield  i:1
  * iadd
  * putfield

* synchronized

* AutomicInteger(CAS)、Lock(CAS/LockSupport/AQS/unself)

总结：volatile是干嘛的

1、可以保证可见性、防止内存重排序

2、#lock->缓存锁(MESI)

3、内存屏障

使用场景：

1、线程的关闭

## 第三节

### 1、synchronized原理分析

### 2、wait和notify

### 3、Lock同步锁





































































