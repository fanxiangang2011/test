# 2018 并发编程

## 第一节

目标

### 1、多线程的发展历史

进程，一次性加载到内存中  CPU时间片，进程只能干一件事情，一个进程包含多个线程

线程

硬件的架构

什么时候使用多线程?

1、通过并行计算提高程序性能

2、等待网络/IO响应导致的耗时问题

### 2、线程的应用

线程有三种实现方式，一种是集成thread类，另一种是实现Runnable接口 ，第三种callable,future

LinkedBlockingQueue

### 3、并发编程的基础

线程的状态：6种

1、NEW

```
A thread that has not yet started is in this state.
初始状态，没有调用start方法
```

2、RUNNABLE

```
A thread executing in the Java virtual machine is in this state.
运行状态，在这之前还有个就绪（READY）
```

3、BLOCKED

```
A thread that is blocked waiting for a monitor lock
    is in this state.
阻塞
	等待阻塞  wait
	同步阻塞  synchrnoized
	其他阻塞  sleep、join
synchronized
```

4、WAITING

```
 A thread that is waiting indefinitely for another thread to
     perform a particular action is in this state.
     等待
```

5、 TIME_WAITING

```
A thread that is waiting for another thread to perform an action
     for up to a specified waiting time is in this state.
时间等待
seelp/wait/join/LockSupport.park()
notify/notifyall/LockSupport.unpark()
```

6、TERMINATED

```
A thread that has exited is in this state.
退出线程的状态
```

cmd jps jstack,查询线程的状态

线程的启动和终止

启动：start，native

终止：stop,一般不用，用优雅的关闭。

​	interrupt:  native方法，原理与volatile一样

​	通过指令的方式:volatile boolean isStop=false,

thread.isInterrupted:返回的结果

Thread.interrupted():对线程的一个复位

### 4、线程安全问题

* 可见性、原子性、有序性

可见性：volatile

原子性（Atomic）：

CPU的高速缓存：

L1---L1 d    L1 i

L2  chche

寄存器

共享    L3 cache

---------------------------------------

主内存



* 缓存一致性的问题？如何解决？

cpu提供了两种方式，

1、总线锁（排它锁），有性能的问题

2、缓存锁：只锁缓存的数据，MESI协议，汇编指令加个LOCK的指令，

MESI协议：在每个缓冲缓存一个标记位

​	M（modify）:当前的缓冲被修改过，

​	I(Invalid)：缓冲失效了

​	E(Exclusive)：独占缓存

​	s(Shared)：共享缓冲

​	嗅探协议

* JMM（应用层面）：

是抽象的内存模型，主要解决可见性、原子性、有序性

java线程--》工作内存（高速缓存）---》load(加载)/store---》主内存（实例对象、静态字段、数组对象）

use 《--load 《---read《---lock

assign--》store---》wite---》unlock

lock：是开发性的(monitorenter/volatile)

## 第二节

### 1、JMM内存模型

*  因为可见性导致的原子性的问题 两个线程同时加1，导致小于3
* 有序性有三个原因
  * 编译器的执行重排序
  * 处理器的指令重拍下
  * 内存系统的重排序

### 2、JMM如果解决原子性、可见性、有序性的问题

* volatile/synchronized/final/j.u.c(java.util.concurrent)
* 原子性  synchronized（monitorenter/monitorexit）
* 可见性 volatile/synchronized/final
* 有序性 volatile/synchronized

### 3、Volatile和synchronized的原理

* volatile  

  * 是轻量级的锁（解决可见性（lock），防止指令重排序），通过指令添加了lock在CPU高速缓存中

  * as-if-serial 

    

    怎么防止指令重排序的？

* 内存屏障

  * 优化屏障
  * 内存屏障
    - 在CPU方面了解什么是内存屏障
      - 高速缓存，数据一致性
    - 乱序访问
    - 在linuxX86上store barrier、load barrier/full barries,解决了顺序重排 的问题，不能解决缓存一致性的问题
      - 防止指令之间的重排序
      - 保证数据的可见性
      - store barrier（写屏障-storestore barrier），强制所有的在storestore内存屏障之前的所有指令先执行、并且发送缓存失效的信号，所有在storestore barrier内存屏障指令之后的store指令，必须在storestore内存屏障之前的指令执行之后再执行。
      - load barrier（读屏障）loadload barrier 
      - storeload (full barries)

* 编译器层面如何解决指令重排序问题？

  * volatile-->flags:ACC_VOLATILE 在accessFlags.hpp-->bytechodeIntepreter.cpp

    ```c++
    int field offset=cache->f2_as_index();
    	if(cache->is_volatile){
    		if(tos_type ==itos){//int,long,char,byte,short,float,double}
    	}
    obj->release int field put(field offset,STACK_INT（-1）)；//值的存储
    
    ```

    oop.inline.cpp

    ```c++
    static void release_store(volatile jint* p,jint  v);
    inline void OrderAccess::release_store(volatile jint* p,jint  v){*p=v;}//语言解绑的内存屏障
    ```

    1、对每天volatile写操作的前面插入storestore barrie

    2、对每个volatile写后面的操作插入storeload barrie

    3、对每个volatile读操作前面插入loadload barrie

    4、对每个volatile读操作后面插入loadstore barrie

    ```c++
    if(os::is MP()){
        //slways use locked addl since is sometimes expensive
    #ifdef AMD64
    	asm volatile("lock;addl$0,0(%%rsp)":::"cc","memory");
    #else
    	asm volatile("lock;addl$0,0(%%esp)":::"cc","memory");
    #endif
    ```

    

* 原则性，对复合操作的原则性是没办法的，

  * getfield  i:1
  * iadd
  * putfield

* synchronized

* AutomicInteger(CAS)、Lock(CAS/LockSupport/AQS/unself)

总结：volatile是干嘛的

1、可以保证可见性、防止内存重排序

2、#lock->缓存锁(MESI)

3、内存屏障

使用场景：

1、线程的关闭

## 第三节

### 1、synchronized原理分析

主要作用：在多线程，保证线程的同步

解决的问题：原则性、可见性、有序性

* synchronized是如何实现锁的

  flags:ACC_SYNCHRONIZED

  monitorenter

  monitorexIt

  monitorexIt

  对象监视器的获取（独占锁 ）ObjectMonitor

  偏向所->轻量级锁->重量级锁

* 为什么任何一点对象都可以成为锁

* 锁存在哪个地方

  对象头：是基础

  oop.hpp/markOop.hpp

  每一个Object->oop/oopDesc对应->mark(存储锁标志的)

  ObjectMonitor(){

  ​	_header       =NULL;//markOop对象头

  ​	_count          =0;

  ​	_waiters 		=0;//等待线程数

  ​	_recursions    =0;//重入次数

  ​	_object            =NULL;

  ​	_owner            =NULL;//指向获得ObjectMonitor对象的线程

  ​	_WaitSet          =NULL;//处于wait状态的线程，会被加入到waitset

  ​	_WaitSetLock  =0;

  ​	Responsible    =NULL;

  ​	succ                  =NULL;

  ​	cxg                    =NULL;//JVM为每个尝试进入synchronized代码段JavaThread创建一个ObjectWaiter并cxq队列中

  ​	FreeNext          =NULL;

  ​	_EntryList          =NULL;//处于等待锁block状态的线程，由ObjectWaiter组成的双向链表，JVM会从该链表中取出一个ObjectWaiter，并唤醒对应的JavaThread

  ​	_SpinFreq          =0;

  ​	_SpinClock         =0;

  ​	OwnerlsThread  =0;

  ​	_previous_owner_tid   =0;//监视器前一个拥有者的线程id

  }

  

  * 锁的获取过程：
  * 自旋锁：for(;;)在1.7之前是通过参数控制的，1.7之后是JVM控制的
  * 偏向锁：锁不仅仅不存在竞争，并且都是由同一个线程获得。
  * 轻量级锁：
  * 重量级锁：锁膨胀，监视器

### 2、wait和notify

 Join调用的是wait方法

1、wait或者notify为什么要先获取锁

对象Object->lock.wait()(释放锁)->waitSet(等待队列)（park）--

​	 释放当前的对象锁

​	使得当前线程进入阻塞

​	notify

2、wait和sleep

### 3、Lock同步锁

## 第四节

我们知道，锁是用来控制对个线程访问共享资源的方式，一般来说，一个锁能防止对个线程同时访问共享资源，在Lock接口出现之前，Java应用程序只能依靠synchronized关键字来实现同步锁的功能，在java5以后，增加了JUC的并发包且提供了Lock接口来实现锁的功能，它提供了与synchroinzed关键字类似的同步功能，只是它比synchronized更灵活，能够显示的获取和释放锁。

### 1、Lock的使用

lock是一个接口，核心的两个方法lock和unlock，它有很多的实现，比如ReentrantLock、ReentrantReadWriteLock;

* ReentrantLock

  重入锁，表示支持重新进入的锁，也就是说，如果当前线程t1通过调用lock方法获取了锁之后，再次调用lock，是不会阻塞在阻塞获取锁的，直接增加重试次数就行了

  ```java
  public class AtomicDemo {
      private static int count=0;
      static Lock lock=new ReentrantLock();
      public static void inc(){
          lock.lock();
          try {
          	Thread.sleep(1);
          } catch (InterruptedException e) {
         		 e.printStackTrace();
          }
          count++;
          lock.unlock();
      }
      public static void main(String[] args) throws InterruptedException {
          for(int i=0;i<1000;i++){
          	new Thread(()->{AtomicDemo.inc();}).start();;
          }
      	Thread.sleep(3000);
          System.out.println("result"+count);
      }
  }
  ```

  

  

* ReentrantReadWriteLock

我们以前理解的锁，基本都是排他锁，也就是这些锁在同一时刻只允许一个线程进行访问，而读写所在同一时刻可
以允许多个线程访问，但是在写线程访问时，所有的读线程和其他写线程都会被阻塞。读写锁维护了一对锁，一个
读锁、一个写锁; 一般情况下，读写锁的性能都会比排它锁好，因为大多数场景读是多于写的。在读多于写的情况
下，读写锁能够提供比排它锁更好的并发性和吞吐量.

```java
public class LockDemo {
	static Map<String,Object> cacheMap=new HashMap<>();
	static ReentrantReadWriteLock rwl=new ReentrantReadWriteLock();
	static Lock read=rwl.readLock();
	static Lock write=rwl.writeLock();
    public static final Object get(String key) {
        System.out.println("开始读取数据");
        read.lock(); //读锁
        try {
        	return cacheMap.get(key);
        }finally {
       		 read.unlock();
   		}
	}
    public static final Object put(String key,Object value){
        write.lock();
        System.out.println("开始写数据");
        try{
        	return cacheMap.put(key,value);
        }finally {
    		write.unlock();
    	}
	}
}
```

在这个案例中，通过hashMap来模拟了一个内存缓存，然后使用读写锁来保证整个缓存的线程安全性。当执行读操作的时候，需要获取读锁，在并发访问的时候，读锁不会被阻塞，因为读操作不会影响执行结果。

在执行写操作时，线程必须要获取写锁，当已经有线程持有写锁的情况下，当前线程会被阻塞，只有当写锁释放以后，其他读写操作才能继续执行。使用读写锁提示读写操作的并发性，也保证每次写操操作对所有的读写操作的可见性。

1. 读锁与读锁可以共享
2. 读锁与写锁不可用共享（排他）
3. 写锁与写锁不可用共享（排他）



* Lock和synchronized简单对比
  * 从层次上，一个是关键字，一个是类，这是最直观的差异
  * 从使用上，lock具备更大的灵活性，可以控制所的释放和获取；而synchronized的锁的释放是被动的，当出现异常或者同步代码块执行完以后，才会释放锁。
  * lock可以判断所的状态，而synchronized无法做到
  * lock可以实现公平锁，非公平锁；而synchronized只有非公平锁

​	

### 2、AQS原理分析

Lock之所以能实现线程安全的锁，只要核心是AQS（AbstractQueuedSynchronizer）,AbstractQueuedSyschronizer提供了一个FIFO队列，可以看做是一个用来实现锁以及其他需要同步功能的框架。这里简称该类为AQS.AQS的使用依靠继承来完成，子类通过继承自AQS并实现锁需的方法来管理同步状态。例如常见的ReentrantLock,CountDownLatch等AQS的两种功能。

从使用上来说，AQS的功能可以分为两种：独占和共享。
独占锁模式下，每次只能有一个线程持有锁，比如前面给大家演示的ReentrantLock就是以独占方式实现的互斥锁
共享锁模式下，允许多个线程同时获取锁，并发访问共享资源，比如ReentrantReadWriteLock。
很显然，独占锁是一种悲观保守的加锁策略，它限制了读/读冲突，如果某个只读线程获取锁，则其他读线程都只
能等待，这种情况下就限制了不必要的并发性，因为读操作并不会影响数据的一致性。共享锁则是一种乐观锁，它
放宽了加锁策略，允许多个执行读操作的线程同时访问共享资源

### 3、Condition

### 4、CountDownLatch、Semaphore

### 5、线程池原理分析





































































