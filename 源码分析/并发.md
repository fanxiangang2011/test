# 2018 并发编程

## 第一节

目标

### 1、多线程的发展历史

进程，一次性加载到内存中  CPU时间片，进程只能干一件事情，一个进程包含多个线程

线程

硬件的架构

什么时候使用多线程?

1、通过并行计算提高程序性能

2、等待网络/IO响应导致的耗时问题

### 2、线程的应用

线程有三种实现方式，一种是集成thread类，另一种是实现Runnable接口 ，第三种callable,future

LinkedBlockingQueue

### 3、并发编程的基础

线程的状态：6种

1、NEW

```
A thread that has not yet started is in this state.
初始状态，没有调用start方法
```

2、RUNNABLE

```
A thread executing in the Java virtual machine is in this state.
运行状态，在这之前还有个就绪（READY）
```

3、BLOCKED

```
A thread that is blocked waiting for a monitor lock
    is in this state.
阻塞
	等待阻塞  wait
	同步阻塞  synchrnoized
	其他阻塞  sleep、join
synchronized
```

4、WAITING

```
 A thread that is waiting indefinitely for another thread to
     perform a particular action is in this state.
     等待
```

5、 TIME_WAITING

```
A thread that is waiting for another thread to perform an action
     for up to a specified waiting time is in this state.
时间等待
seelp/wait/join/LockSupport.park()
notify/notifyall/LockSupport.unpark()
```

6、TERMINATED

```
A thread that has exited is in this state.
退出线程的状态
```

cmd jps jstack,查询线程的状态

线程的启动和终止

启动：start，native

终止：stop,一般不用，用优雅的关闭。

​	interrupt:  native方法，原理与volatile一样

​	通过指令的方式:volatile boolean isStop=false,

thread.isInterrupted:返回的结果

Thread.interrupted():对线程的一个复位

### 4、线程安全问题

* 可见性、原子性、有序性

可见性：volatile

原子性（Atomic）：

CPU的高速缓存：

L1---L1 d    L1 i

L2  chche

寄存器

共享    L3 cache

---------------------------------------

主内存



* 缓存一致性的问题？如何解决？

cpu提供了两种方式，

1、总线锁（排它锁），有性能的问题

2、缓存锁：只锁缓存的数据，MESI协议，汇编指令加个LOCK的指令，

MESI协议：在每个缓冲缓存一个标记位

​	M（modify）:当前的缓冲被修改过，

​	I(Invalid)：缓冲失效了

​	E(Exclusive)：独占缓存

​	s(Shared)：共享缓冲

​	嗅探协议

* JMM（应用层面）：

是抽象的内存模型，主要解决可见性、原子性、有序性

java线程--》工作内存（高速缓存）---》load(加载)/store---》主内存（实例对象、静态字段、数组对象）

use 《--load 《---read《---lock

assign--》store---》wite---》unlock

lock：是开发性的(monitorenter/volatile)

## 第二节

### 1、JMM内存模型

*  因为可见性导致的原子性的问题 两个线程同时加1，导致小于3
* 有序性有三个原因
  * 编译器的执行重排序
  * 处理器的指令重拍下
  * 内存系统的重排序

### 2、JMM如果解决原子性、可见性、有序性的问题

* volatile/synchronized/final/j.u.c(java.util.concurrent)
* 原子性  synchronized（monitorenter/monitorexit）
* 可见性 volatile/synchronized/final
* 有序性 volatile/synchronized

### 3、Volatile和synchronized的原理

* volatile  

  * 是轻量级的锁（解决可见性（lock），防止指令重排序），通过指令添加了lock在CPU高速缓存中

  * as-if-serial 

    

    怎么防止指令重排序的？

* 内存屏障

  * 优化屏障
  * 内存屏障
    - 在CPU方面了解什么是内存屏障
      - 高速缓存，数据一致性
    - 乱序访问
    - 在linuxX86上store barrier、load barrier/full barries,解决了顺序重排 的问题，不能解决缓存一致性的问题
      - 防止指令之间的重排序
      - 保证数据的可见性
      - store barrier（写屏障-storestore barrier），强制所有的在storestore内存屏障之前的所有指令先执行、并且发送缓存失效的信号，所有在storestore barrier内存屏障指令之后的store指令，必须在storestore内存屏障之前的指令执行之后再执行。
      - load barrier（读屏障）loadload barrier 
      - storeload (full barries)

* 编译器层面如何解决指令重排序问题？

  * volatile-->flags:ACC_VOLATILE 在accessFlags.hpp-->bytechodeIntepreter.cpp

    ```c++
    int field offset=cache->f2_as_index();
    	if(cache->is_volatile){
    		if(tos_type ==itos){//int,long,char,byte,short,float,double}
    	}
    obj->release int field put(field offset,STACK_INT（-1）)；//值的存储
    
    ```

    oop.inline.cpp

    ```c++
    static void release_store(volatile jint* p,jint  v);
    inline void OrderAccess::release_store(volatile jint* p,jint  v){*p=v;}//语言解绑的内存屏障
    ```

    1、对每天volatile写操作的前面插入storestore barrie

    2、对每个volatile写后面的操作插入storeload barrie

    3、对每个volatile读操作前面插入loadload barrie

    4、对每个volatile读操作后面插入loadstore barrie

    ```c++
    if(os::is MP()){
        //slways use locked addl since is sometimes expensive
    #ifdef AMD64
    	asm volatile("lock;addl$0,0(%%rsp)":::"cc","memory");
    #else
    	asm volatile("lock;addl$0,0(%%esp)":::"cc","memory");
    #endif
    ```

    

* 原则性，对复合操作的原则性是没办法的，

  * getfield  i:1
  * iadd
  * putfield

* synchronized

* AutomicInteger(CAS)、Lock(CAS/LockSupport/AQS/unself)

总结：volatile是干嘛的

1、可以保证可见性、防止内存重排序

2、#lock->缓存锁(MESI)

3、内存屏障

使用场景：

1、线程的关闭

## 第三节

### 1、synchronized原理分析

主要作用：在多线程，保证线程的同步

解决的问题：原则性、可见性、有序性

* synchronized是如何实现锁的

  flags:ACC_SYNCHRONIZED

  monitorenter

  monitorexIt

  monitorexIt

  对象监视器的获取（独占锁 ）ObjectMonitor

  偏向所->轻量级锁->重量级锁

* 为什么任何一点对象都可以成为锁

* 锁存在哪个地方

  对象头：是基础

  oop.hpp/markOop.hpp

  每一个Object->oop/oopDesc对应->mark(存储锁标志的)

  ObjectMonitor(){

  ​	_header       =NULL;//markOop对象头

  ​	_count          =0;

  ​	_waiters 		=0;//等待线程数

  ​	_recursions    =0;//重入次数

  ​	_object            =NULL;

  ​	_owner            =NULL;//指向获得ObjectMonitor对象的线程

  ​	_WaitSet          =NULL;//处于wait状态的线程，会被加入到waitset

  ​	_WaitSetLock  =0;

  ​	Responsible    =NULL;

  ​	succ                  =NULL;

  ​	cxg                    =NULL;//JVM为每个尝试进入synchronized代码段JavaThread创建一个ObjectWaiter并cxq队列中

  ​	FreeNext          =NULL;

  ​	_EntryList          =NULL;//处于等待锁block状态的线程，由ObjectWaiter组成的双向链表，JVM会从该链表中取出一个ObjectWaiter，并唤醒对应的JavaThread

  ​	_SpinFreq          =0;

  ​	_SpinClock         =0;

  ​	OwnerlsThread  =0;

  ​	_previous_owner_tid   =0;//监视器前一个拥有者的线程id

  }

  

  * 锁的获取过程：
  * 自旋锁：for(;;)在1.7之前是通过参数控制的，1.7之后是JVM控制的
  * 偏向锁：锁不仅仅不存在竞争，并且都是由同一个线程获得。
  * 轻量级锁：
  * 重量级锁：锁膨胀，监视器

### 2、wait和notify

 Join调用的是wait方法

1、wait或者notify为什么要先获取锁

对象Object->lock.wait()(释放锁)->waitSet(等待队列)（park）--

​	 释放当前的对象锁

​	使得当前线程进入阻塞

​	notify

2、wait和sleep

### 3、Lock同步锁

## 第四节

我们知道，锁是用来控制对个线程访问共享资源的方式，一般来说，一个锁能防止对个线程同时访问共享资源，在Lock接口出现之前，Java应用程序只能依靠synchronized关键字来实现同步锁的功能，在java5以后，增加了JUC的并发包且提供了Lock接口来实现锁的功能，它提供了与synchroinzed关键字类似的同步功能，只是它比synchronized更灵活，能够显示的获取和释放锁。

### 1、Lock的使用

lock是一个接口，核心的两个方法lock和unlock，它有很多的实现，比如ReentrantLock、ReentrantReadWriteLock;

* ReentrantLock

  重入锁，表示支持重新进入的锁，也就是说，如果当前线程t1通过调用lock方法获取了锁之后，再次调用lock，是不会阻塞在阻塞获取锁的，直接增加重试次数就行了

  ```java
  public class AtomicDemo {
      private static int count=0;
      static Lock lock=new ReentrantLock();
      public static void inc(){
          lock.lock();
          try {
          	Thread.sleep(1);
          } catch (InterruptedException e) {
         		 e.printStackTrace();
          }
          count++;
          lock.unlock();
      }
      public static void main(String[] args) throws InterruptedException {
          for(int i=0;i<1000;i++){
          	new Thread(()->{AtomicDemo.inc();}).start();;
          }
      	Thread.sleep(3000);
          System.out.println("result"+count);
      }
  }
  ```

  

  

* ReentrantReadWriteLock

我们以前理解的锁，基本都是排他锁，也就是这些锁在同一时刻只允许一个线程进行访问，而读写所在同一时刻可
以允许多个线程访问，但是在写线程访问时，所有的读线程和其他写线程都会被阻塞。读写锁维护了一对锁，一个
读锁、一个写锁; 一般情况下，读写锁的性能都会比排它锁好，因为大多数场景读是多于写的。在读多于写的情况
下，读写锁能够提供比排它锁更好的并发性和吞吐量.

```java
public class LockDemo {
	static Map<String,Object> cacheMap=new HashMap<>();
	static ReentrantReadWriteLock rwl=new ReentrantReadWriteLock();
	static Lock read=rwl.readLock();
	static Lock write=rwl.writeLock();
    public static final Object get(String key) {
        System.out.println("开始读取数据");
        read.lock(); //读锁
        try {
        	return cacheMap.get(key);
        }finally {
       		 read.unlock();
   		}
	}
    public static final Object put(String key,Object value){
        write.lock();
        System.out.println("开始写数据");
        try{
        	return cacheMap.put(key,value);
        }finally {
    		write.unlock();
    	}
	}
}
```

在这个案例中，通过hashMap来模拟了一个内存缓存，然后使用读写锁来保证整个缓存的线程安全性。当执行读操作的时候，需要获取读锁，在并发访问的时候，读锁不会被阻塞，因为读操作不会影响执行结果。

在执行写操作时，线程必须要获取写锁，当已经有线程持有写锁的情况下，当前线程会被阻塞，只有当写锁释放以后，其他读写操作才能继续执行。使用读写锁提示读写操作的并发性，也保证每次写操操作对所有的读写操作的可见性。

1. 读锁与读锁可以共享
2. 读锁与写锁不可用共享（排他）
3. 写锁与写锁不可用共享（排他）



* Lock和synchronized简单对比
  * 从层次上，一个是关键字，一个是类，这是最直观的差异
  * 从使用上，lock具备更大的灵活性，可以控制所的释放和获取；而synchronized的锁的释放是被动的，当出现异常或者同步代码块执行完以后，才会释放锁。
  * lock可以判断所的状态，而synchronized无法做到
  * lock可以实现公平锁，非公平锁；而synchronized只有非公平锁

		

### 2、AQS原理分析

Lock之所以能实现线程安全的锁，只要核心是AQS（AbstractQueuedSynchronizer）,AbstractQueuedSyschronizer提供了一个FIFO队列，可以看做是一个用来实现锁以及其他需要同步功能的框架。这里简称该类为AQS.AQS的使用依靠继承来完成，子类通过继承自AQS并实现锁需的方法来管理同步状态。例如常见的ReentrantLock,CountDownLatch等AQS的两种功能。

从使用上来说，AQS的功能可以分为两种：独占和共享。
独占锁模式下，每次只能有一个线程持有锁，比如前面给大家演示的ReentrantLock就是以独占方式实现的互斥锁
共享锁模式下，允许多个线程同时获取锁，并发访问共享资源，比如ReentrantReadWriteLock。
很显然，独占锁是一种悲观保守的加锁策略，它限制了读/读冲突，如果某个只读线程获取锁，则其他读线程都只
能等待，这种情况下就限制了不必要的并发性，因为读操作并不会影响数据的一致性。共享锁则是一种乐观锁，它
放宽了加锁策略，允许多个执行读操作的线程同时访问共享资源

**AQS的内部实现**

同步器依赖内部的同步队列（一个FIFO双向队列）来完成同步状态的管理，当前线程获取同步状态失败时，同步器会将当前线程以及等待状态等信息构造成为一个节点（Node）并将其加入同步队列，同时会阻塞当前线程，当同步状态释放时，会把首节点中的线程唤醒，使其再次尝试获取同步状态

Node的主要属性如下：

```
static final class Node {
    int waitStatus; //表示节点的状态，包含cancelled（取消）；condition 表示节点在等待condition
    也就是在condition队列中
    Node prev; //前继节点
    Node next; //后继节点
    Node nextWaiter; //存储在condition队列中的后继节点
    Thread thread; //当前线程
}
```

AQS类底层的数据结构使使用双向链表，是队列的一种实现。包括一个head节点和一个tail节点，分别表示终点和尾结点，其中头结点不存储Thread，仅保存next结点的引用。

图片略

当一个线程成功获取了同步状态（或者锁），其他线程将无法获取到同步状态，转而被构造成为节点并加入到同步队列中，而这个加入队列的过程必须要保证线程安全，因此同步器提供了一个基于CAS的设置尾节点和当前节点，只有设置成功后，当前节点才正式与之前的尾节点建立关联。

图片略

同步队列遵循FIFO，首节点是获取同步状态成功的节点，首节点的线程在释放同步状态时，将会唤醒后继节点，而后继节点将会在获取同步状态成功时将自己设置为首节点。

设置首节点是通过获取同步状态成功的线程来完成的，由于只有一个线程能够成功获取到同步状态，因此设置头节
点的方法并不需要使用CAS来保证，它只需要将首节点设置成为原首节点的后继节点并断开原首节点的next引用即
可

* compareAndSet

AQS中，除了本身的链表结构以外，还有一个很关键的功能，就是CAS，这个是保证在多线程并发的情况下保证线
程安全的前提下去把线程加入到AQS中的方法,可以简单理解为乐观锁

```java
private final boolean compareAndSetHead(Node update) {
	return unsafe.compareAndSwapObject(this, headOffset, null, update);
}
```

这个方法里面，首先用到了unsafe类，(Unsefe类是在sun.misc包下，不属于java标准。但是很多java的基础类库，包括一些被广泛使用的高性能开发库都是基于unsafe类开发的，比如Netty、Hadoop、Kafka等；Unsafe可认为是Java中留下得到后面，提供了一些低层次操作，如直接内存访问、线程调度等)

然后调用了compareAndSwapObject这个方法

```java
public final native boolean compareAndSwapObject(Object var1, long var2, Object var4,
Object var5);
```

这个是一个native方法，第一个参数为需要改变的对象，第二个为偏移量（即之前求出来的headOffset的值），第三个为期待的值，第四个为更新后的值，

整个方法的作用是如果当前失控的值等于预期值var4相等，则更新为新的期望值var5，如果更新成功，则返回true，否则返回false;

这里传入一个headOffset是什么呢？在下面的代码中，通过unsafe.objectFieldOffset

```java
private static final long headOffset;
private static final long tailOffset;
private static final long waitStatusOffset;
private static final long nextOffset;
static{
    try{
        stateOffset=unsafe.objectFieldOffset(AbstractQueuedSynchronizer.class.getDeclaredField("state"));
        headOffset=unsafe.objectFieldOffset(AbstractQueuedSynchronizer.class.getDeclaredField("head"));
   tailOffset=unsafe.objectFieldOffset(AbstractQueuedSynchronizer.class.getDeclaredField("tail"));
        waitStatusOffset=unsafe.objectFieldOffset(AbstractQueuedSynchronizer.class.getDeclaredField("waitStatus"));
        nextOffset=unsafe.objectFieldOffset(AbstractQueuedSynchronizer.class.getDeclaredField("next"));
        
    }
}
```

然后通过反射获取了AQS类中的成员变量，并且这个成员变量被volatile修饰的

```java
 private transient volatile Node head;

    /**
     * Tail of the wait queue, lazily initialized.  Modified only via
     * method enq to add new wait node.
     */
    private transient volatile Node tail;

    /**
     * The synchronization state.
     */
    private volatile int state;
```

**unsafe.objectFieldOffset**
headOffset这个是指类中相应字段在该类的偏移量，在这里具体即是指head这个字段在AQS类的内存中相对于该
类首地址的偏移量。
一个Java对象可以看成是一段内存，每个字段都得按照一定的顺序放在这段内存里，通过这个方法可以准确地告诉
你某个字段相对于对象的起始内存地址的字节偏移。用于在后面的compareAndSwapObject中，去根据偏移量找
到对象在内存中的具体位置
这个方法在unsafe.cpp文件中，代码如下

```
UNSAFE_ENTRY(jboolean, Unsafe_CompareAndSwapObject(JNIEnv *env, jobject unsafe, jobject
obj, jlong offset, jobject e_h, jobject x_h))
UnsafeWrapper("Unsafe_CompareAndSwapObject");
oop x = JNIHandles::resolve(x_h); // 新值
oop e = JNIHandles::resolve(e_h); // 预期值
oop p = JNIHandles::resolve(obj);
HeapWord* addr = (HeapWord *)index_oop_from_field_offset_long(p, offset);// 在内存中的
具体位置
oop res = oopDesc::atomic_compare_exchange_oop(x, addr, e, true);// 调用了另一个方法，实
际上就是通过cas操作来替换内存中的值是否成功
jboolean success = (res == e); // 如果返回的res等于e，则判定满足compare条件（说明res应该为
内存中的当前值），但实际上会有ABA的问题
if (success) // success为true时，说明此时已经交换成功（调用的是最底层的cmpxchg指令）
update_barrier_set((void*)addr, x); // 每次Reference类型数据写操作时，都会产生一个Write
Barrier暂时中断操作，配合垃圾收集器
return success;
UNSAFE_END
```

所以其实compareAndSet这个方法，最终调用的是unsafe类的compareAndSwap，这个指令会对内存中的共享数
据做原子的读写操作。

1. 首先， cpu会把内存中将要被更改的数据与期望值做比较
2. 然后，当两个值相等时，cpu才会将内存中的对象替换为新的值。否则，不做变更操作
3. 最后，返回操作执行结果
    很显然，这是一种乐观锁的实现思路。

**ReentrantLock的实现原理分析** 

之所以叫重入锁是因为同一个线程如果已经获得了锁，那么后续该线程调用lock方法时不需要再次获取锁，也就是
不会阻塞；重入锁提供了两种实现，一种是非公平的重入锁，另一种是公平的重入锁。怎么理解公平和非公平呢？
如果在绝对时间上，先对锁进行获取的请求一定先被满足获得锁，那么这个锁就是公平锁，反之，就是不公平的。
简单来说公平锁就是等待时间最长的线程最优先获取锁。

**源码分析**

```
public void lock() {
        sync.lock();
    }
```

这个是获取锁的入口，调用了sync.lock； sync是一个实现了AQS的抽象类，这个类的主要作用是用来实现同步控
制的，并且sync有两个实现，一个是NonfairSync(非公平锁)、另一个是FailSync(公平锁)； 我们先来分析一下非公
平锁的实现

**NonfairSync.lock**

```java
final void lock() {
if (compareAndSetState(0, 1)) //这是跟公平锁的主要区别,一上来就试探锁是否空闲,如果可以插队，
则设置获得锁的线程为当前线程
//exclusiveOwnerThread属性是AQS从父类AbstractOwnableSynchronizer中继承的属性，用来保存当前占用
同步状态的线程
setExclusiveOwnerThread(Thread.currentThread());
else
acquire(1); //尝试去获取锁
}
```

compareAndSetState，这个方法在前面提到过了，再简单讲解一下，通过cas算法去改变state的值，而这个state
是什么呢？ 在AQS中存在一个变量state，对于ReentrantLock来说，如果state=0表示无锁状态、如果state>0表示有锁状态。
所以在这里，是表示当前的state如果等于0，则替换为1，如果替换成功表示获取锁成功了
由于ReentrantLock是可重入锁，所以持有锁的线程可以多次加锁，经过判断加锁线程就是当前持有锁的线程时
（即exclusiveOwnerThread==Thread.currentThread()），即可加锁，每次加锁都会将state的值+1，state等于几，就代表当前持有锁的线程加了几次锁;解锁时每解一次锁就会将state减1，state减到0后，锁就被释放掉，这时其它线程可以加锁；

**AbstractQueuedSynchronizer.acquire**
如果CAS操作未能成功，说明state已经不为0，此时继续acquire(1)操作,acquire是AQS中的方法 当多个线程同时进
入这个方法时，首先通过cas去修改state的状态，如果修改成功表示竞争锁成功，竞争失败的，tryAcquire会返回
false

```
public final void acquire(int arg) {
    if (!tryAcquire(arg) &&
    acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
    selfInterrupt();
}
```

这个方法的主要作用是
Ø 尝试获取独占锁，获取成功则返回，否则
Ø 自旋获取锁，并且判断中断标识，如果中断标识为true，则设置线程中断
Ø addWaiter方法把当前线程封装成Node，并添加到队列的尾部

**NonfairSync.tryAcquire**
tryAcquire方法尝试获取锁，如果成功就返回，如果不成功，则把当前线程和等待状态信息构适成一个Node节
点，并将结点放入同步队列的尾部。然后为同步队列中的当前节点循环等待获取锁，直到成功

```
protected final boolean tryAcquire(int acquires) {
	return nonfairTryAcquire(acquires);
}
```

**nofairTryAcquire**

这里可以看非公平锁的涵义，即获取锁并不会严格根据争用锁的先后顺序决定。这里的实现逻辑类似synchroized
关键字的偏向锁的做法，即可重入而不用进一步进行锁的竞争，也解释了ReentrantLock中Reentrant的意义

```
final boolean nonfairTryAcquire(int acquires) {
final Thread current = Thread.currentThread();
int c = getState(); //获取当前的状态，前面讲过，默认情况下是0表示无锁状态
if (c == 0) {
if (compareAndSetState(0, acquires)) { //通过cas来改变state状态的值，如果更新成功，表
示获取锁成功, 这个操作外部方法lock()就做过一次，这里再做只是为了再尝试一次，尽量以最简单的方式获取锁。
setExclusiveOwnerThread(current);
return true;
}
}
else if (current == getExclusiveOwnerThread()) {//如果当前线程等于获取锁的线程，表示重入，
直接累加重入次数
int nextc = c + acquires;
if (nextc < 0) // overflow 如果这个状态值越界，抛出异常；如果没有越界，则设置后返回true
throw new Error("Maximum lock count exceeded");
setState(nextc);
return true;
}
如果状态不为0，且当前线程不是owner，则返回false。
return false; //获取锁失败，返回false
}
```

**addWaiter**
当前锁如果已经被其他线程锁持有，那么当前线程来去请求锁的时候，会进入这个方法,这个方法主要是把当前线程
封装成node，添加到AQS的链表中

```
private Node addWaiter(Node mode) {
Node node = new Node(Thread.currentThread(), mode); //创建一个独占的Node节点,mode为排他
模式
// 尝试快速入队,如果失败则降级至full enq
Node pred = tail; // tail是AQS的中表示同步队列队尾的属性，刚开始为null，所以进行enq(node)方
法
if (pred != null) {
node.prev = pred;
if (compareAndSetTail(pred, node)) { // 防止有其他线程修改tail,使用CAS进行修改,如果失
败则降级至full enq
pred.next = node; // 如果成功之后旧的tail的next指针再指向新的tail,成为双向链表
return node;
}
}
enq(node); // 如果队列为null或者CAS设置新的tail失败
return node;
}
```

**enq**

enq就是通过自旋操作把当前节点加入到队列中

```
private Node enq(final Node node) {
for (;;) { //无效的循环，为什么采用for(;;)，是因为它执行的指令少，不占用寄存器
Node t = tail;// 此时head, tail都为null
if (t == null) { // Must initialize// 如果tail为null则说明队列首次使用,需要进行初始化
if (compareAndSetHead(new Node()))// 设置头节点,如果失败则存在竞争,留至下一轮循环
tail = head; // 用CAS的方式创建一个空的Node作为头结点，因为此时队列中只一个头结
点，所以tail也指向head，第一次循环执行结束
} else {
//进行第二次循环时，tail不为null，进入else区域。将当前线程的Node结点的prev指向tail，然后使用CAS将
tail指向Node
//这部分代码和addWaiter代码一样，将当前节点添加到队列
node.prev = t;
if (compareAndSetTail(t, node)) {
t.next = node; //t此时指向tail,所以可以CAS成功，将tail重新指向CNode。此时t为更
新前的tail的值，即指向空的头结点，t.next=node，就将头结点的后续结点指向Node，返回头结点
return t;
}
}
}
}
```

代码运行到这里，aqs队列的结构就是这样一个表现

**acquireQueued**

addWaiter返回了插入的节点，作为acquireQueued方法的入参,这个方法主要用于争抢锁

```
final boolean acquireQueued(final Node node, int arg) {
boolean failed = true;
try {
boolean interrupted = false;
for (;;) {
final Node p = node.predecessor();// 获取prev节点,若为null即刻抛出
NullPointException
if (p == head && tryAcquire(arg)) {// 如果前驱为head才有资格进行锁的抢夺
setHead(node); // 获取锁成功后就不需要再进行同步操作了,获取锁成功的线程作为新的
head节点
//凡是head节点,head.thread与head.prev永远为null, 但是head.next不为null
p.next = null; // help GC
failed = false; //获取锁成功
return interrupted;
}
//如果获取锁失败，则根据节点的waitStatus决定是否需要挂起线程
if (shouldParkAfterFailedAcquire(p, node) &&
parkAndCheckInterrupt())// 若前面为true,则执行挂起,待下次唤醒的时候检测中断的标
志
interrupted = true;
}
} finally {
if (failed) // 如果抛出异常则取消锁的获取,进行出队(sync queue)操作
cancelAcquire(node);
}
}
```

原来的head节点释放锁以后，会从队列中移除，原来head节点的next节点会成为head节点

**shouldParkAfterFailedAcquire**

从上面的分析可以看出，只有队列的第二个节点可以有机会争用锁，如果成功获取锁，则此节点晋升为头节点。对
于第三个及以后的节点，if (p == head)条件不成立，首先进行shouldParkAfterFailedAcquire(p, node)操作
shouldParkAfterFailedAcquire方法是判断一个争用锁的线程是否应该被阻塞。它首先判断一个节点的前置节点的状态是否为Node.SIGNAL，如果是，是说明此节点已经将状态设置-如果锁释放，则应当通知它，所以它可以安全的阻塞了，返回true

```
private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) {
int ws = pred.waitStatus; //前继节点的状态
if (ws == Node.SIGNAL)//如果是SIGNAL状态，意味着当前线程需要被unpark唤醒
return true;
如果前节点的状态大于0，即为CANCELLED状态时，则会从前节点开始逐步循环找到一个没有被“CANCELLED”节点设置
为当前节点的前节点，返回false。在下次循环执行shouldParkAfterFailedAcquire时，返回true。这个操作实
际是把队列中CANCELLED的节点剔除掉。
if (ws > 0) {// 如果前继节点是“取消”状态，则设置 “当前节点”的 “当前前继节点” 为 “‘原前继节
点'的前继节点”。
do {
node.prev = pred = pred.prev;
} while (pred.waitStatus > 0);
pred.next = node;
} else { // 如果前继节点为“0”或者“共享锁”状态，则设置前继节点为SIGNAL状态。
/*
* waitStatus must be 0 or PROPAGATE. Indicate that we
* need a signal, but don't park yet. Caller will need to
* retry to make sure it cannot acquire before parking.
*/
compareAndSetWaitStatus(pred, ws, Node.SIGNAL);
}
return false;
}
```

解读：假如有t1,t2两个线程都加入到了链表中
img
如果head节点位置的线程一直持有锁，那么t1和t2就是挂起状态，而HEAD以及Thread1的的awaitStatus都是
SIGNAL，在多次尝试获取锁失败以后，就会通过下面的方法进行挂起（这个地方就是避免了惊群效应，每个节点
只需要关心上一个节点的状态即可）
img
SIGNAL：值为-1，表示当前节点的的后继节点将要或者已经被阻塞，在当前节点释放的时候需要unpark后继节
点；
CONDITION：值为-2，表示当前节点在等待condition，即在condition队列中；
PROPAGATE：值为-3，表示releaseShared需要被传播给后续节点（仅在共享模式下使用）；

**parkAndCheckInterrupt**
如果shouldParkAfterFailedAcquire返回了true，则会执行：“parkAndCheckInterrupt()”方法，它是通过
LockSupport.park(this)将当前线程挂起到WATING状态，它需要等待一个中断、unpark方法来唤醒它，通过这样
一种FIFO的机制的等待，来实现了Lock的操作

```
private final boolean parkAndCheckInterrupt() {
LockSupport.park(this);// LockSupport提供park()和unpark()方法实现阻塞线程和解除线程阻塞
return Thread.interrupted();
}
```

**ReentrantLock.unlock**
加锁的过程分析完以后，再来分析一下释放锁的过程，调用release方法，这个方法里面做两件事，1，释放锁 ；
2，唤醒park的线程

```
public final boolean release(int arg) {
if (tryRelease(arg)) {
Node h = head;
if (h != null && h.waitStatus != 0)
unparkSuccessor(h);
return true;
}
return false;
}
```

**tryRelease**
这个动作可以认为就是一个设置锁状态的操作，而且是将状态减掉传入的参数值（参数是1），如果结果状态为0，
就将排它锁的Owner设置为null，以使得其它的线程有机会进行执行。 在排它锁中，加锁的时候状态会增加1（当
然可以自己修改这个值），在解锁的时候减掉1，同一个锁，在可以重入后，可能会被叠加为2、3、4这些值，只
有unlock()的次数与lock()的次数对应才会将Owner线程设置为空，而且也只有这种情况下才会返回true。

```
protected final boolean tryRelease(int releases) {
int c = getState() - releases; // 这里是将锁的数量减1
if (Thread.currentThread() != getExclusiveOwnerThread())// 如果释放的线程和获取锁的线程
不是同一个，抛出非法监视器状态异常
throw new IllegalMonitorStateException();
boolean free = false;
if (c == 0) {
// 由于重入的关系，不是每次释放锁c都等于0，
// 直到最后一次释放锁时，才会把当前线程释放
free = true;
setExclusiveOwnerThread(null);
}
setState(c);
return free;
}
```

**LockSupport**
LockSupport类是Java6引入的一个类，提供了基本的线程同步原语。LockSupport实际上是调用了Unsafe类里的
函数，归结到Unsafe里，只有两个函数：

```
public native void unpark(Thread jthread);
public native void park(boolean isAbsolute, long time);
```

unpark函数为线程提供“许可(permit)”，线程调用park函数则等待“许可”。这个有点像信号量，但是这个“许可”是不
能叠加的，“许可”是一次性的。
permit相当于0/1的开关，默认是0，调用一次unpark就加1变成了1.调用一次park会消费permit，又会变成0。 如
果再调用一次park会阻塞，因为permit已经是0了。直到permit变成1.这时调用unpark会把permit设置为1.每个线
程都有一个相关的permit，permit最多只有一个，重复调用unpark不会累积
在使用LockSupport之前，我们对线程做同步，只能使用wait和notify，但是wait和notify其实不是很灵活，并且耦
合性很高，调用notify必须要确保某个线程处于wait状态，而park/unpark模型真正解耦了线程之间的同步，先后
顺序没有没有直接关联，同时线程之间不再需要一个Object或者其它变量来存储状态，不再需要关心对方的状态。

**公平锁和非公平锁的区别**

锁的公平性是相对于获取锁的顺序而言的，如果是一个公平锁，那么锁的获取顺序就应该符合请求的绝对时间顺
序，也就是FIFO。 在上面分析的例子来说，只要CAS设置同步状态成功，则表示当前线程获取了锁，而公平锁则不一样，差异点有两个

**FairSync.tryAcquire**

```
final void** lock() {
acquire(1);
}
```

非公平锁在获取锁的时候，会先通过CAS进行抢占，而公平锁则不会

**FairSync.tryAcquire**

```
protected final boolean* tryAcquire(int acquires) {
final Thread current = Thread.currentThread*();
int c = getState();
if (c == 0) {
if (!hasQueuedPredecessors() &&
compareAndSetState(0, acquires)) {
setExclusiveOwnerThread(current);
return true;
}
}
else if (current == getExclusiveOwnerThread()) {
int nextc = c + acquires;
if (nextc < 0)
throw new Error("Maximum lock count exceeded");
setState(nextc);
return true;
}
return false;
}
```

这个方法与nonfairTryAcquire(int acquires)比较，不同的地方在于判断条件多了hasQueuedPredecessors()方
法，也就是加入了[同步队列中当前节点是否有前驱节点]的判断，如果该方法返回true，则表示有线程比当前线程
更早地请求获取锁，因此需要等待前驱线程获取并释放锁之后才能继续获取锁。

### 3、Condition

通过前面的课程学习，我们知道任意一个Java对象，都拥有一组监视器方法（定义在java.lang.Object上），主要包括wait()、notify()以及notifyAll()方法，这些方法与synchronized同步关键字配合，可以实现等待/通知模式
JUC包提供了Condition来对锁进行精准控制，Condition是一个多线程协调通信的工具类，可以让某些线程一起等
待某个条件（condition），只有满足条件时，线程才会被唤醒。

**condition使用案例**

**ConditionWait**

```
public class ConditionDemoWait implements Runnable{
private Lock lock;
private Condition condition;
public ConditionDemoWait(Lock lock, Condition condition){
this.lock=lock;
this.condition=condition;
}
@Override
public void run() {
System.out.println("begin -ConditionDemoWait");
try {
lock.lock();
condition.await();
System.out.println("end - ConditionDemoWait");
} catch (InterruptedException e) {
e.printStackTrace();
}finally {
lock.unlock();
}
}
}
```

**ConditionSignal**

```
public class** ConditionDemoSignal implements Runnable{
private Lock lock;
private Condition condition;
public ConditionDemoSignal(Lock lock, Condition condition){
this.lock=lock;
this.condition=condition;
}
@Override
public void run() {
System.out.println("begin -ConditionDemoSignal");
try {
lock.lock();
condition.signal();
System.out.println("end - ConditionDemoSignal");
}finally {
lock.unlock();
}
}
}
```

通过这个案例简单实现了wait和notify的功能，当调用await方法后，当前线程会释放锁并等待，而其他线程调用
condition对象的signal或者signalall方法通知并被阻塞的线程，然后自己执行unlock释放锁，被唤醒的线程获得之
前的锁继续执行，最后释放锁。
所以，condition中两个最重要的方法，一个是await，一个是signal方法
await:把当前线程阻塞挂起
signal:唤醒阻塞的线程

**await方法**

调用Condition的await()方法（或者以await开头的方法），会使当前线程进入等待队列并释放锁，同时线程状态变
为等待状态。当从await()方法返回时，当前线程一定获取了Condition相关联的锁

```
public final void await() throws InterruptedException {
if (Thread.interrupted())
throw new InterruptedException();
Node node = addConditionWaiter(); //创建一个新的节点，节点状态为condition，采用的数据结构
仍然是链表
int savedState = fullyRelease(node); //释放当前的锁，得到锁的状态，并唤醒AQS队列中的一个线
程
int interruptMode = 0;
//如果当前节点没有在同步队列上，即还没有被signal，则将当前线程阻塞
//isOnSyncQueue 判断当前 node 状态,如果是 CONDITION 状态,或者不在队列上了,就继续阻塞,还在队列上且
不是 CONDITION 状态了,就结束循环和阻塞
while (!isOnSyncQueue(node)) {//第一次判断的是false，因为前面已经释放锁了
LockSupport.park(this); // 第一次总是 park 自己,开始阻塞等待
// 线程判断自己在等待过程中是否被中断了,如果没有中断,则再次循环,会在 isOnSyncQueue 中判断自己是否在队
列上.
if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)
break;
}
// 当这个线程醒来,会尝试拿锁, 当 acquireQueued 返回 false 就是拿到锁了.
// interruptMode != THROW_IE -> 表示这个线程没有成功将 node 入队,但 signal 执行了 enq 方
法让其入队了.
// 将这个变量设置成 REINTERRUPT.
if (acquireQueued(node, savedState) && interruptMode != THROW_IE)
interruptMode = REINTERRUPT;
// 如果 node 的下一个等待者不是 null, 则进行清理,清理 Condition 队列上的节点.
// 如果是 null ,就没有什么好清理的了.
if (node.nextWaiter != null) // clean up if cancelled
unlinkCancelledWaiters();
// 如果线程被中断了,需要抛出异常.或者什么都不做
if (interruptMode != 0)
reportInterruptAfterWait(interruptMode);
}
```

**signal**

调用Condition的signal()方法，将会唤醒在等待队列中等待时间最长的节点（首节点），在唤醒节点之前，会将节
点移到同步队列中

```
public final void signal() {
if (!isHeldExclusively()) //先判断当前线程是否获得了锁
throw new IllegalMonitorStateException();
Node first = firstWaiter; // 拿到 Condition 队列上第一个节点
if (first != null)
doSignal(first);
}
private void doSignal(Node first) {
do {
if ( (firstWaiter = first.nextWaiter) == null)// 如果第一个节点的下一个节点是 null,
那么, 最后一个节点也是 null.
lastWaiter = null; // 将 next 节点设置成 null
first.nextWaiter = null;
} while (!transferForSignal(first) &&
(first = firstWaiter) != null);
}
```

该方法先是 CAS 修改了节点状态，如果成功，就将这个节点放到 AQS 队列中，然后唤醒这个节点上的线程。此
时，那个节点就会在 await 方法中苏醒

```
final boolean transferForSignal(Node node) {
if (!compareAndSetWaitStatus(node, Node.CONDITION, 0))
return false;
Node p = enq(node);
int ws = p.waitStatus;
// 如果上一个节点的状态被取消了, 或者尝试设置上一个节点的状态为 SIGNAL 失败了(SIGNAL 表示: 他的
next 节点需要停止阻塞),
if (ws > 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL))
LockSupport.unpark(node.thread); // 唤醒输入节点上的线程.
return true;
}
```



## 第五节

### 限制

JUC中提供了几个比较常用的并发工具类，比如CountDownLatch、CyclicBarrier、Semaphore。 其实在以前我们课堂的演示代码中，或多或少都有用到过这样一些api，接下来我们会带大家去深入研究一些常用的api。

#### CountDownLatch

countdownlatch是一个同步工具类，它允许一个或多个线程一直等待，直到其他线程的操作执行完毕再执行。从
命名可以解读到countdown是倒数的意思，类似于我们倒计时的概念。

countdownlatch提供了两个方法，一个是countDown，一个是await， countdownlatch初始化的时候需要传入一个整数，在这个整数倒数到0之前，调用了await方法的程序都必须要等待，然后通过countDown来倒数。

```
public static void main(String[] args) throws InterruptedException {
    CountDownLatch countDownLatch=new CountDownLatch(3);
    new Thread(()->{
   	 countDownLatch.countDown();
    },"t1").start();
    new Thread(()->{
   	 countDownLatch.countDown();
    },"t2").start();
    new Thread(()->{
        countDownLatch.countDown();
     },"t3").start();
     countDownLatch.await();
     System.out.println("所有线程执行完毕");
}
```

从代码的实现来看，有点类似join的功能，但是比join更加灵活。CountDownLatch构造函数会接收一个int类型的
参数作为计数器的初始值，当调用CountDownLatch的countDown方法时，这个计数器就会减一。
通过await方法去阻塞去阻塞主流程.

**使用场景**

1、通过countdownlatch实现最大的并行请求，也就是可以让N个线程同时执行，这个我也是在课堂上写的比较多的

2、比如应用程序启动之前，需要确保相应的服务已经启动，比如我们之前在讲zookeeper的时候，通过原生的api连接的地方有用到countDownLatch

**源码分析**

CountDownLatch类存在一个内部类Sync，上节课我们讲过，它是一个同步工具，一定继承了
AbstractQueuedSynchronizer。很显然，CountDownLatch实际上是是使得线程阻塞了，既然涉及到阻塞，就一
定涉及到AQS队列

**await**

await函数会使得当前线程在countdownlatch倒计时到0之前一直等待，除非线程别中断；从源码中可以得知await方法会转发到Sync的acquireSharedInterruptibly

```java 
public void await() throws InterruptedException { sync.acquireSharedInterruptibly(1); }
```

**acquireSharedInterruptibly**

这块代码主要是判断当前线程是否获取到了共享锁; 上一节课提到过，AQS有两种锁类型，一种是共享锁，一种是
独占锁，在这里用的是共享锁； 为什么要用共享锁，因为CountDownLatch可以多个线程同时通过。

```java
public final void acquireSharedInterruptibly(int arg)throws InterruptedException {
    if (Thread.interrupted()) //判断线程是否中断
    throw new InterruptedException();
    if (tryAcquireShared(arg) < 0) //如果等于0则返回1，否则返回-1，返回-1表示需要阻塞
    doAcquireSharedInterruptibly(arg);
}
在这里，state的意义是count，如果计数器为0，表示不需要阻塞，否则，只有在满足条件的情况下才会被唤醒	
```

**doAcquireSharedInterruptibly**

获取共享锁

```java
private void doAcquireSharedInterruptibly(int arg)
throws InterruptedException {
final Node node = addWaiter(Node.SHARED); //创建一个共享模式的节点添加到队列中
boolean failed = true;
try {
    for (;;) { //自旋等待共享锁释放，也就是等待计数器等于0。
        final Node p = node.predecessor(); //获得当前节点的前一个节点
        if (p == head) {
        	int r = tryAcquireShared(arg);//就判断尝试获取锁
            if (r >= 0) {//r>=0表示计数器已经归零了，则释放当前的共享锁
            setHeadAndPropagate(node, r);
            p.next = null; // help GC
            failed = false;
            return;
   		 }
	}
//当前节点不是头节点，则尝试让当前线程阻塞，第一个方法是判断是否需要阻塞，第二个方法是阻塞
    if (shouldParkAfterFailedAcquire(p, node) &&
    parkAndCheckInterrupt())
    throw new InterruptedException();
}
} finally {
if (failed)
	cancelAcquire(node);
}
}
```

**setHeadAndPropagate**

![](D:\yuanma\test\源码分析\并发5-1.jpg)

PROPAGATE：值为-3，表示releaseShared需要被传播给后续节点

```java
private void setHeadAndPropagate(Node node, int propagate) {
        Node h = head; // 记录头节点
        setHead(node); //设置当前节点为头节点
        //前面传过来的propagate是1，所以会进入下面的代码
        if (propagate > 0 || h == null || h.waitStatus < 0 ||
        (h = head) == null || h.waitStatus < 0) {
            Node s = node.next; //获得当前节点的下一个节点，如果下一个节点是空表示当前节点为最后一个节
            点，或者下一个节点是share节点
            if (s == null || s.isShared())
            doReleaseShared(); //唤醒下一个共享节点
        }
}
```

**doReleaseShared**

释放共享锁，通知后面的节点

```java
private void doReleaseShared() {
    for (;;) {
        Node h = head; //获得头节点
        if (h != null && h != tail) { //如果头节点不为空且不等于tail节点
                int ws = h.waitStatus;
                if (ws == Node.SIGNAL) { //头节点状态为SIGNAL，
                if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) //修改当前头节点的状态为0,
                避免下次再进入到这个里面
                continue; // loop to recheck cases
                unparkSuccessor(h); //释放后续节点
            }
            else if (ws == 0 &&
                !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))
                continue; // loop on failed CAS
            }
            if (h == head) // loop if head changed
            break;
    }
}
```

**countdown**

以共享模式释放锁，并且会调用tryReleaseShared函数，根据判断条件也可能会调用doReleaseShared函数

```java
public final boolean releaseShared(int arg) {
    if (tryReleaseShared(arg)) { //如果为true，表示计数器已归0了
        doReleaseShared(); //唤醒处于阻塞的线程
        return true;
    }
    return false;
}
```

**tryReleaseShared**

这里主要是对state做原子递减，其实就是我们构造的CountDownLatch的计数器，如果等于0返回true，否则返回
false

```java
protected boolean tryReleaseShared(int releases) {
// Decrement count; signal when transition to zero
    for (;;) {
        int c = getState();
        if (c == 0)
        return false;
        int nextc = c-1;
        if (compareAndSetState(c, nextc))
        return nextc == 0;
    }
}
```



#### Semaphore

semaphore也就是我们常说的信号灯，semaphore可以控制同时访问的线程个数，通过acquire获取一个许可，如果没有就等待，通过release释放一个许可。有点类似限流的作用。叫信号灯的原因也和他的用处有关，比如某商场就5个停车位，每个停车位只能停一辆车，如果这个时候来了10辆车，必须要等前面有空的车位才能进入。

**案例**

```java
public class SemaphoreTest {
    public static void main(String[] args) {
        Semaphore semaphore=new Semaphore(5);
        for (int i=0;i<10;i++){
            new Car(i,semaphore).start();
        }
    }
    static class Car extends Thread{
        private int num;
        private Semaphore semaphore;
        public Car(int num,Semaphore semaphore){
            this.num=num;
            this.semaphore=semaphore;
        }

        @Override
        public void run() {
            try {
                semaphore.acquire();
                System.out.println("第"+num+"占用一个停车位");
                TimeUnit.SECONDS.sleep(2);
                System.out.println("第"+num+"俩车走喽");
                semaphore.release();
            }catch (InterruptedException e){
                e.printStackTrace();
            }

        }
    }

}
```

**使用场景**

可以实现对某些接口访问的限流

**源码分析**

semaphore也是基于AQS来实现的，内部使用state表示许可数量；它的实现方式和CountDownLatch的差异点在
于acquireSharedInterruptibly中的tryAcquireShared方法的实现，这个方法是在Semaphore方法中重写的

入口

```java
 public void acquire() throws InterruptedException {
        sync.acquireSharedInterruptibly(1);
    }
```

**acquireSharedInterruptibly**

```java
  public final void acquireSharedInterruptibly(int arg)
            throws InterruptedException {
        if (Thread.interrupted())
            throw new InterruptedException();
        if (tryAcquireShared(arg) < 0)
            doAcquireSharedInterruptibly(arg);
    }
```

**tryAcquireShared**

在semaphore中存在公平和非公平的方式，和重入锁是一样的，如果通过FairSync表示公平的信号量、
NonFairSync表示非公平的信号量；公平和非公平取决于是否按照FIFO队列中的顺序去分配Semaphore所维护的
许可，我们来看非公平锁的实现

**nonfairTryAcquireShared**

自旋去获得一个许可，如果许可获取失败，也就是remaining<0的情况下，让当前线程阻塞

```java
final int nonfairTryAcquireShared(int acquires) {
            for (;;) {
                int available = getState();
                int remaining = available - acquires;
                if (remaining < 0 ||
                    compareAndSetState(available, remaining))
                    return remaining;
            }
        }
```

**releaseShared**

releaseShared方法的逻辑也很简单，就是通过线程安全的方式去增加一个许可，如果增加成功，则触发释放一个
共享锁，也就是让之前处于阻塞的线程重新运行

```java
  public final boolean releaseShared(int arg) {
        if (tryReleaseShared(arg)) {
            doReleaseShared();
            return true;
        }
        return false;
    }
```

**tryReleaseShared**  增加令牌数

```java
 protected final boolean tryReleaseShared(int releases) {
            for (;;) {
                int current = getState();
                int next = current + releases;
                if (next < current) // overflow
                    throw new Error("Maximum permit count exceeded");
                if (compareAndSetState(current, next))
                    return true;
            }
        }
```





### 原子操作

当在多线程情况下，同时更新一个共享变量，由于我们前面讲过的原子性问题，可能得不到预期的结果。如果要达
到期望的结果，可以通过synchronized来加锁解决，因为synchronized会保证多线程对共享变量的访问进行排
队。

在Java5以后，提供了原子操作类，这些原子操作类提供了一种简单、高效以及线程安全的更新操作。而由于变量
的类型很多，所以Atomic一共提供了12个类分别对应四种类型的原子更新操作，基本类型、数组类型、引用类
型、属性类型

基本类型对应：AtomicBoolean、AtomicInteger、AtomicLong
数组类型对应：AtomicIntegerArray、AtomicLongArray、AtomicReferenceArray
引用类型对应：AtomicReference、AtomicReferenceFieldUpdater、AtomicMarkableReference
字段类型对应：AtomicIntegerFieldUpdater、AtomicLongFieldUpdater、AtomicStampedReference

#### Automic原子操作的使用

```java
private static AtomicInteger count=new AtomicInteger(0);
public static synchronized void inc() {
    try {
    Thread.sleep(1);
    } catch (InterruptedException e) {
        e.printStackTrace();
    }
	count.getAndIncrement();
}
public static void main(String[] args) throws InterruptedException {
    for(int i=0;i<1000;i++){
        new Thread(()-> {
            SafeDemo.inc();
        }).start();
    }
    Thread.sleep(4000);
    System.out.println(count.get());
}
```



#### Atomicinteger实现原理

由于所有的原子操作类都是大同小异的，所以我们只分析其中一个原子操作类

```java
public final int getAndIncrement() {
	return unsafe.getAndAddInt(this, valueOffset, 1);
}
```

大家又会发现一些熟悉的东西，就是unsafe。调用unsafe类中的getAndAddInt方法，这个方法如下

```java
public final int getAndAddInt(Object var1, long var2, int var4) {
	int var5;
    do {
    	var5 = this.getIntVolatile(var1, var2);// 方法获取对象中offset偏移地址对应的整型field的值
    } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));
    	return var5;
}
```

通过循环以及cas的方式实现原子更新，从而达到在多线程情况下仍然能够保证原子性的目的。大家会发现，只要
基本的东西搞明白以后，剩下的都比较容易理解了

### 线程池

Java中的线程池是运用场景最多的并发框架，几乎所有需要异步或并发执行任务的程序都可以使用线程池。线程池
就像数据库连接池的作用类似，只是线程池是用来重复管理线程避免创建大量线程增加开销。所以合理的使用线程
池可以:

1. 降低创建线程和销毁线程的性能开销
2. 合理的设置线程大小可以避免因为线程超出硬件资源瓶颈带来的问题，类似起到了限流作用；线程是稀缺资源，如果无线创建，会造成系统稳定性问题。

#### 线程池的使用

JDK 为我们内置了几种常见线程池的实现，均可以使用 Executors 工厂类创建
为了更好的控制多线程，JDK提供了一套线程框架Executor，帮助开发人员有效的进行线程控制。它们都在
java.util.concurrent包中，是JDK并发包的核心。
其中有一个比较重要的类:Executors，他扮演着线程工厂的角色，我们通过Executors可以创建特定功能的线程池

**newFixedThreadPool**：该方法返回一个固定数量的线程池，线程数不变，当有一个任务提交时，若线程池
中空闲，则立即执行，若没有，则会被暂缓在一个任务队列中，等待有空闲的线程去执行。
**newSingleThreadExecutor**: 创建一个线程的线程池，若空闲则执行，若没有空闲线程则暂缓在任务队列中。
**newCachedThreadPool**：返回一个可根据实际情况调整线程个数的线程池，不限制最大线程数量，若用空
闲的线程则执行任务，若无任务则不创建线程。并且每一个空闲线程会在60秒后自动回收
**newScheduledThreadPool**: 创建一个可以指定线程的数量的线程池，但是这个线程池还带有延迟和周期性执行
任务的功能，类似定时器。

```java
public class Test implements Runnable{
@Override
public void run() {
    try {
        Thread.sleep(10);
    } catch (InterruptedException e) {
    e.printStackTrace();
    }
	System.out.println(Thread.currentThread().getName());
}
    static ExecutorService service=Executors.newFixedThreadPool(3);
    public static void main(String[] args) {
        for(int i=0;i<100;i++) {
            service.execute(new Test());
        }
    	service.shutdown();
    }
}
```

设置了3个固定线程大小的线程池来跑100

**submit和execute的区别**

执行一个任务，可以使用submit和execute，这两者有什么区别呢？

1. execute只能接受Runnable类型的任务
2. submit不管是Runnable还是Callable类型的任务都可以接受，但是Runnable返回值均为void，所以使用Future的get（）获得的还是Null

#### ThreadpoolExecutor

前面说的四种线程池构建工具，都是基于ThreadPoolExecutor 类，它的构造函数参数

```java
public ThreadPoolExecutor(int corePoolSize, //核心线程数量
int maximumPoolSize, //最大线程数
long keepAliveTime, //超时时间,超出核心线程数量以外的线程空余存活时间
TimeUnit unit, //存活时间单位
BlockingQueue<Runnable> workQueue, //保存执行任务的队列
ThreadFactory threadFactory,//创建新线程使用的工厂
RejectedExecutionHandler handler //当任务无法执行的时候的处理方式
) {
this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,
Executors.defaultThreadFactory(), defaultHandler);
}
```

分别看一下前面提到的几个初始化工具类的构造以及原理

**newFixedThreadPool**

```java
public static ExecutorService newFixedThreadPool(int nThreads) {
return new ThreadPoolExecutor(nThreads, nThreads,
0L, TimeUnit.MILLISECONDS,
new LinkedBlockingQueue<Runnable>());
}
```

FixedThreadPool 的核心线程数和最大线程数都是指定值，也就是说当线程池中的线程数超过核心线程数后，任务都会被放到阻塞队列中。另外 keepAliveTime 为 0，也就是超出核心线程数量以外的线程空余存活时间而这里选用的阻塞队列是 LinkedBlockingQueue，使用的是默认容量 Integer.MAX_VALUE，相当于没有上限

这个线程池执行任务的流程如下：

1. 线程数少于核心线程数，也就是设置的线程数时，新建线程执行的任务
2. 线程数等于核心线程数，将任务加入阻塞队列
3. 由于队列容量非常大，可以一直添加
4. 执行完任务的线程反复去队列中去任务执行

**用途**：FixedThreadPool 用于负载比较大的服务器，为了资源的合理利用，需要限制当前线程数量

**newCachedThreadPool**

```java
public static ExecutorService newCachedThreadPool() {
    return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
    60L, TimeUnit.SECONDS,
    new SynchronousQueue<Runnable>());
}
```

CachedThreadPool 创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程; 并且没有核心线程，非核心线程数无上限，但是每个空闲的时间只有 60 秒，超过后就会被回收。
它的执行流程如下：

1. 没有科学线程，直接向SynchronousQueue中提交任务
2. 如果有空闲线程，就去去除任务执行；如果没有空闲线程，就新建一个
3. 执行完成任务的线程有60秒生存时间，如果在这个时间内可以接到新任务，就可以局限活下去，否则就被回收

**newSingleThreadExecutor**

创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先
级)执行

#### 线程池的源码分析

ThreadPoolExecutor是线程池的核心，提供了线程池的实现。ScheduledThreadPoolExecutor继承了ThreadPoolExecutor，并另外提供一些调度方法以支持定时和周期任务。Executers是工具类，主要用来创建线程
池对象我们把一个任务提交给线程池去处理的时候，线程池的处理过程是什么样的呢？首先直接来看看定义

**线程数量和线程池状态管理**

线程池用一个AtomicInteger来保存 [线程数量] 和 [线程池状态] ,一个int数值一共有32位,高3位用于保存运行状态,
低29位用于保存线程数量

```java
private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); //一个原子操作类
private static final int COUNT_BITS = Integer.SIZE - 3; //32-3
private static final int CAPACITY = (1 << COUNT_BITS) - 1; //将1的二进制向右位移29位,再减
1表示最大线程容量
//运行状态保存在int值的高3位 (所有数值左移29位)
private static final int RUNNING = -1 << COUNT_BITS;// 接收新任务,并执行队列中的任务
private static final int SHUTDOWN = 0 << COUNT_BITS;// 不接收新任务,但是执行队列中的任务
private static final int STOP = 1 << COUNT_BITS;// 不接收新任务,不执行队列中的任务,中
断正在执行中的任务
private static final int TIDYING = 2 << COUNT_BITS; //所有的任务都已结束,线程数量为0,处
于该状态的线程池即将调用terminated()方法
private static final int TERMINATED = 3 << COUNT_BITS;// terminated()方法执行完成
// Packing and unpacking ctl
private static int runStateOf(int c) { return c & ~CAPACITY; } //获取运行状态
private static int workerCountOf(int c) { return c & CAPACITY; } //获取线程数量
```

**execute**

通过线程池的核心方法了解线程池中这些参数的含义

```java
public void execute(Runnable command) {
    if (command == null)
    throw new NullPointerException();
    int c = ctl.get();
    if (workerCountOf(c) < corePoolSize) {//1.当前池中线程比核心数少，新建一个线程执行任务
        if (addWorker(command, true))
        return;
        c = ctl.get();
    }
    if (isRunning(c) && workQueue.offer(command)) {//2.核心池已满，但任务队列未满，添加到队列
中
int recheck = ctl.get();
//任务成功添加到队列以后，再次检查是否需要添加新的线程，因为已存在的线程可能被销毁了
if (! isRunning(recheck) && remove(command))
reject(command);//如果线程池处于非运行状态，并且把当前的任务从任务队列中移除成功，则拒
绝该任务
else if (workerCountOf(recheck) == 0)//如果之前的线程已被销毁完，新建一个线程
addWorker(null, false);
}
else if (!addWorker(command, false)) //3.核心池已满，队列已满，试着创建一个新线程
reject(command); //如果创建新线程失败了，说明线程池被关闭或者线程池完全满了，拒绝任务
}
```

![](D:\yuanma\test\源码分析\并发-5-2.jpg)

































































